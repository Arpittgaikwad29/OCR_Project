OCR_using_gimini.py - {
    import os
from google.generativeai import GenerativeModel, configure
from PIL import Image

# Set your API key
os.environ["GOOGLE_API_KEY"] = "AIzaSyC_yR_Z1BNvkL1ixrejs2aqvGHSXK2CwvE"
configure(api_key=os.environ["GOOGLE_API_KEY"])

# Load image
image = Image.open("p6.jpg")

# Use Gemini Flash model
model = GenerativeModel("gemini-2.0-flash")

# Stream response
response = model.generate_content(
    [image, "Only extract the exact text content from the image. Don't include any explanation or additional information."],
    stream=True
)

# Print only extracted text
print("".join(part.text for part in response).strip())

}

correction.py - {
    import os
from google.generativeai import GenerativeModel, configure

# Set your API key
os.environ["GOOGLE_API_KEY"] = "AIzaSyC_yR_Z1BNvkL1ixrejs2aqvGHSXK2CwvE"
configure(api_key=os.environ["GOOGLE_API_KEY"])

# Use Gemini model
model = GenerativeModel("gemini-2.0-flash")

# Input text
input_text = """Dr L H Hiranandani Hospital
Kiran Agoural.
23/olite 201
F. 69
Dysphgrat hy (Coy for than gody)
Cab
COC TSH T3TY
Nival Meker 1130/
SUPT Creat CAP
Liquid Toll dich
On fedh
11 Am The fron
Ap Tricani mos
2- Hygody
C. mylara 19-cod"""

# Prompt for correction
prompt = f"Correct only the spelling mistakes in the following text. Do not add, remove,Correct obvious mistakes to make the statements clear and meaningful if needed. or change anything else:\n\n{input_text}"

# Generate response
response = model.generate_content(prompt)

# Print corrected text
print(response.text.strip())
}

understanding.py - {
    import os
from google.generativeai import GenerativeModel, configure

# Set your API key
os.environ["GOOGLE_API_KEY"] = "AIzaSyC_yR_Z1BNvkL1ixrejs2aqvGHSXK2CwvE"
configure(api_key=os.environ["GOOGLE_API_KEY"])

# Use Gemini model
model = GenerativeModel("gemini-2.0-flash")

# Input text
input_text = """Dr. L. H. Hiranandani Hospital
Kiran Agoural
23/olite 201
F. 69
Dysphagia (Cough for than gody)
Cab
COC TSH T3TY
Nival Meker 1130/
SUPT Creat CAP
Liquid Toll dich
On fedh
11 Am The fron
Ap Tricani mos
2- Hygody
C. mylara 19-cod"""

# Prompt for extracting only valuable relational information
prompt = f"Extract only the meaningful relationships or medically relevant information from the following text. Do not add anything extra:\n\n{input_text}"

# Generate response
response = model.generate_content(prompt)

# Print extracted info
print(response.text.strip())

}

FHIR_format.py - {
    import os
from google.generativeai import GenerativeModel, configure

# Set your API key
os.environ["GOOGLE_API_KEY"] = "AIzaSyC_yR_Z1BNvkL1ixrejs2aqvGHSXK2CwvE"
configure(api_key=os.environ["GOOGLE_API_KEY"])

# Use Gemini model
model = GenerativeModel("gemini-2.0-flash")

# Input medical text
input_text = """**Patient:** Kiran Agoural
*   **Sex:** Female
*   **Age:** 69
*   **Diagnosis/Symptoms:** Dysphagia (cough)
*   **Medical History/Relevant Information:** Cab
*   **Medications/Labs:** COC, TSH, T3, T4
*   **SUPT Creat CAP**"""

# Prompt for FHIR conversion with PHI hidden
prompt = f"""
Convert the following medical report into FHIR (Fast Healthcare Interoperability Resources) JSON format.
- Do NOT include any personal identifying information (e.g. name, date of birth, caste).
- Only include medically relevant data such as diagnosis, medications, allergies, observations, and treatment plan.
- Do not add any extra information. Keep it minimal and structured.

Text:
{input_text}
"""

# Generate response
response = model.generate_content(prompt)

# Print FHIR-compliant output
print(response.text.strip())

}

create_graphDB.py - {
    import os
from google.generativeai import GenerativeModel, configure
from neo4j import GraphDatabase

# Set your API key
os.environ["GOOGLE_API_KEY"] = "AIzaSyC_yR_Z1BNvkL1ixrejs2aqvGHSXK2CwvE"
configure(api_key=os.environ["GOOGLE_API_KEY"])

# Gemini model
model = GenerativeModel("gemini-2.0-flash")

# Your input medical text
input_text = """*   **Patient:** Kiran Agoural
*   **Age:** 69
*   **Sex:** Female (F)
*   **Diagnosis/Symptoms:** Dysphagia (cough)
*   **Medical History:** Cab (Possible abbreviation for a condition)
*   **Medications/Tests:** COC, TSH, T3 T4, SUPT Creat CAP
*   **Recommendations:** Liquid diet"""

# Prompt to Gemini
prompt = f"""
You are a Cypher query generator for Neo4j.

1. First, generate a Cypher query to delete all existing nodes and relationships.
2. Then, from the given medical text, extract medically relevant information (e.g., diagnosis, medications, observations, treatment plan) and generate Cypher queries to insert them into the graph.
3. Do NOT include any personal info like name, birthdate, or caste.
4. Output only raw Cypher queries without triple backticks or extra explanations.

Text:
{input_text}
"""

# Generate the response
response = model.generate_content(prompt)

# Strip code blocks if present
raw_cypher = response.text.strip()
if raw_cypher.startswith("```"):
    raw_cypher = "\n".join(line for line in raw_cypher.splitlines() if not line.startswith("```"))

# Connect to Neo4j
uri = "neo4j+s://a66a629b.databases.neo4j.io"
username = "neo4j"
password = "39Ak-WMIJZEh8oU2m7pXeN0ESFw74m1bogLfqsm3APY"

driver = GraphDatabase.driver(uri, auth=(username, password))

# Function to run Cypher queries
def run_cypher_queries(driver, queries):
    with driver.session() as session:
        for query in queries.split(";"):
            query = query.strip()
            if query:
                print("Running query:", query)
                session.run(query)

# Run the cleaned Cypher queries
run_cypher_queries(driver, raw_cypher)

# Close driver
driver.close()
}

final_output.py - {
    from langchain_neo4j import Neo4jGraph
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Initialize Neo4j Graph
graph = Neo4jGraph(
    url="neo4j+s://a66a629b.databases.neo4j.io",
    username="neo4j",
    password="39Ak-WMIJZEh8oU2m7pXeN0ESFw74m1bogLfqsm3APY",
    database="neo4j"
)

# Initialize Gemini LLM
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key="AIzaSyC_yR_Z1BNvkL1ixrejs2aqvGHSXK2CwvE")

# Get schema information from the database - use as property not method
schema = graph.schema
print("Database Schema:")
print(schema)

# Query to get Patient1's health records
patient_query = """
MATCH (p:Patient {name: 'Patient1'})-[r]->(n)
RETURN p, r, n
"""
patient_data = graph.query(patient_query)
print("\nPatient Data:")
print(patient_data)

# Create a prompt template for the LLM
prompt_template = """
You are a medical AI assistant. Based on the following patient data from a Neo4j database, 
please analyze the health records for Patient1 and provide:
1. A brief summary of the patient's condition
2. A short prescription recommendation
3. Recommendations for further actions

Patient Data:
{patient_data}

Database Schema:
{schema}

Your response should be formatted with clear sections for Summary, Prescription, and Recommendations.
"""

prompt = PromptTemplate(
    input_variables=["patient_data", "schema"],
    template=prompt_template
)

# Create an LLM chain
chain = LLMChain(llm=llm, prompt=prompt)

# Run the chain
result = chain.invoke({
    "patient_data": str(patient_data), 
    "schema": schema
})

# Display results
print("\nðŸ“‹ Summary + ðŸ’Š Prescription + âœ… Recommendations:")
print(result['text'])
}